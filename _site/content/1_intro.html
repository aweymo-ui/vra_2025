<!DOCTYPE html>
<html lang="en" class="h-100">
  <head prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# article: http://ogp.me/ns/article#">
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<title>Introduction | Image Extraction for Overhead Scans and Archeological Photographs</title>
<meta name="description" content="Presentation for the 2025 Visual Resources Association Conference">
<meta name="keywords" content="">
<meta name="author" content="Andrew Weymouth">
<link rel="icon" type="image/png" href="http://localhost:4000/vra_2025/favicon.png">

<!--
  _      __         __        __           ______               __     __     
 | | /| / /__  ____/ /__ ___ / /  ___  ___/_  __/__ __ _  ___  / /__ _/ /____ 
 | |/ |/ / _ \/ __/  '_/(_-</ _ \/ _ \/ _ \/ / / -_)  ' \/ _ \/ / _ `/ __/ -_)
 |__/|__/\___/_/ /_/\_\/___/_//_/\___/ .__/_/  \__/_/_/_/ .__/_/\_,_/\__/\__/ 
                                    /_/                /_/                    

    built with workshop-template-b, evanwill, https://github.com/evanwill/workshop-template-b
--> 
   
<!-- Open Graph meta -->
<meta property="og:title" content="Introduction | Image Extraction for Overhead Scans and Archeological Photographs" />
<meta property="og:type" content="website" />
<meta property="og:description" content="Presentation for the 2025 Visual Resources Association Conference" />
<meta property="og:image" content="http://localhost:4000/vra_2025/images/banner.png" />
<meta property="og:site_name" content="Image Extraction for Overhead Scans and Archeological Photographs" />
<meta property="og:url" content="http://localhost:4000/vra_2025/content/1_intro.html" />
<meta property="og:locale" content="en_US" />
<!-- schema.org JSON-LD -->
<script type="application/ld+json">{ "@context":"http://schema.org", "@type":"WebPage", "headline":"Introduction | Image Extraction for Overhead Scans and Archeological Photographs", "author": { "@type":"Person", "name":"Andrew Weymouth"}, "description":"Presentation for the 2025 Visual Resources Association Conference", "image": "http://localhost:4000/vra_2025/images/banner.png", "url":"http://localhost:4000/vra_2025/content/1_intro.html" }</script>

<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Anta&display=swap" rel="stylesheet">

<link rel="stylesheet" href="/vra_2025/assets/lib/spotlight.min.css">
<link rel="stylesheet" href="/vra_2025/assets/lib/bootstrap.min.css" type="text/css">
<link rel="stylesheet" href="/vra_2025/assets/css/styles.css">

<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100..900;1,100..900&display=swap" rel="stylesheet">

<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Crimson+Text:ital,wght@0,400;0,600;0,700;1,400;1,600;1,700&family=EB+Garamond:ital,wght@0,400..800;1,400..800&display=swap" rel="stylesheet">


<!-- Last build date: 2025-08-07 -->
  </head>

  <body class="d-flex flex-column h-100">
    <div id="skip-to-content"><a href="#maincontent">Skip to main content</a></div>
    <header>
    <nav class="navbar navbar-light pb-lg-0 border-bottom" style="background-color: #F0F8FF;">
    <div class="container">
        <h1 class="navbar-brand" style="white-space: normal;"><a href="/vra_2025/">
            
            Image Extraction for Overhead Scans and Archeological Photographs
        </a></h1>
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#mainNav" aria-controls="mainNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse justify-content-end" id="mainNav">
            <ul class="navbar-nav nav-tabs justify-content-end">
            
                <li class="nav-item">
                    <a class="nav-link active p-3 h-100" href="/vra_2025/content/1_intro.html">
                        
                            Introduction
                        
                    </a>
                </li>
            
                <li class="nav-item">
                    <a class="nav-link p-3 h-100" href="/vra_2025/content/2_ed.html">
                        
                            edge_detector tool
                        
                    </a>
                </li>
            
                <li class="nav-item">
                    <a class="nav-link p-3 h-100" href="/vra_2025/content/3_ie.html">
                        
                            image_extractor tool
                        
                    </a>
                </li>
            
                <li class="nav-item">
                    <a class="nav-link p-3 h-100" href="/vra_2025/content/4_findings.html">
                        
                            Findings
                        
                    </a>
                </li>
            
            </ul>  
        </div>
    </div>
</nav>

    </header>

    <main id="maincontent" role="main" aria-label="Content" class="flex-shrink-0">
      
      <div class="container my-4">
<h1>Introduction</h1>

<div class="ms-5 mb-3 border-bottom">
    </div>
    
<div class="my-4">

<p><br /></p>

<p>My name is Andrew Weymouth, the Digital Initiatives Librarian for University of Idaho and today I’ll be discussing two practical applications implementing computer vision that can facilitate processing large numbers of digital visual resources.</p>

<div class="symbol-container">
    <p class="symbol">&#10042;</p>
</div>

<p>The team I’m a part of in the Center for Digital Initiatives and Learning consists of three other people and a small group of student workers, collaborating with the five members of our Special Collections department to create and maintain the 150 digital collections on our main institutional repository as well as the many other, more customized fellowship projects. I also develop digital tools and workflows to enhance transcription, tagging, and image processing, in order to make the university’s audio, text, and visual resources more discoverable for researchers.</p>

<figure class="figure d-block text-center p-3">
    <a class="spotlight" href="/vra_2025/images/vra_01.gif"><img data-src="/vra_2025/images/vra_01.gif" alt="Screen capture of a patron scrolling through the U of I digital collections, going from the main browse page to a collection and then an item level resource." class="figure-img img-fluid lazyload" /></a><figcaption class="figure-caption">The U of I Digital Collections, moving from the main browse page to a collection and down to the item level</figcaption></figure>

<p>Both of the tools I’ll be speaking about today have their origins in finding practical solutions to repetitive, digital work that comes after the hands-on arranging, research, cataloguing and description work in the archive. Considering I work with technology quite a bit, I would broadly self identify as critical towards AI applications to cultural heritage work, which I think you’ll find reflective in the coding approach, where sets of algorithms and neural networks are implemented on guardrails within a programmatic workflow, to make results more scalable and reproducible.</p>

<p><br /></p>

<h2 id="definitions">Definitions</h2>

<p><br /></p>

<p>It might be helpful to begin with some definitions of what resources these tools implement. Both tools are written in <code class="language-plaintext highlighter-rouge">Python</code>, a general purpose, readable programming language, and they are hosted in <code class="language-plaintext highlighter-rouge">GitHub</code>, a version controlled platform for hosting software development projects.</p>

<figure class="figure d-block text-center p-3">
    <a class="spotlight" href="/vra_2025/images/vra_07.png"><img data-src="/vra_2025/images/vra_07.png" alt="A visual analogy of the definitions, where large language models are within a sphere of neural networks within a sphere of machine learning, that is within a sphere of algorithms. The first three are yellow, indicating they are all trained, and the outer ring of algorithms is green, indicating it is not necessarily trained. There is a box of yellow and green spheres representing Python libraries and three green dots representing untrained, deterministic path utilities." style="width:75%;" class="figure-img img-fluid lazyload" /></a><figcaption class="figure-caption">Representation of algorithmic shared characteristics</figcaption></figure>

<p>The first tool I’ll discuss implements an artificial intelligence resource. At the moment, most of us would associate AI with <code class="language-plaintext highlighter-rouge">large language models</code> that are trained on text and reproduce human language styled output. In contrast, this tool is a more general <code class="language-plaintext highlighter-rouge">neural network</code>, computer architecture in which processors are interconnected in a manner suggestive of the human brain. The second tool utilizes <code class="language-plaintext highlighter-rouge">machine learning</code> which is a computational method that enables a computer to learn to perform tasks by analyzing a large dataset without being explicitly programmed, in that case to focus on pattern recognition. All of the other resources these tools utilize are <code class="language-plaintext highlighter-rouge">Python libraries</code>, wrappers that distribute any of the above models as well as <code class="language-plaintext highlighter-rouge">path utilities</code>, which are untrained, deterministic functions.</p>

<p><br /></p>


</div>

</div>
      
    </main>

    <footer class="site-footer bg-light-blue mt-auto">
  <div class="container">
    <nav class="mt-3 mb-4">
      <ul class="nav nav-pills nav-fill">
        
        <li class="nav-item"><a class="nav-link h3 active" href="/vra_2025/content/1_intro.html">Introduction</a></li>
        
        <li class="nav-item"><a class="nav-link h3" href="/vra_2025/content/2_ed.html">edge_detector tool</a></li>
        
        <li class="nav-item"><a class="nav-link h3" href="/vra_2025/content/3_ie.html">image_extractor tool</a></li>
        
        <li class="nav-item"><a class="nav-link h3" href="/vra_2025/content/4_findings.html">Findings</a></li>
        
      </ul>
    </nav>
    <div class="row align-items-center pb-5">
        <div id="footer-title" class="col-md">
          <a class="h5" href="/vra_2025/">Image Extraction for Overhead Scans and Archeological Photographs</a>
          <br>
          <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC BY-NC-ND 4.0, </a> 2025 <a href="https://github.com/aweymo-ui">Andrew Weymouth</a>
        </div>
        <div class="col-md">
          
          <script>
            function site_search() {
              var query = document.getElementById("site-search").value;
              window.open("/vra_2025/search/index.html?q=" + encodeURIComponent(query), "_self" );
            }
          </script>
          <form class="form-inline my-2 my-lg-0 float-end" role="search" id="search" onsubmit="site_search(); return false;">
            <div class="input-group">
              <input id="site-search" class="form-control" type="text" placeholder="Search" aria-label="Search box">
              <div class="input-group-append">
                <button class="btn btn-secondary" type="submit"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-search" viewBox="0 0 16 16"> <path d="M11.742 10.344a6.5 6.5 0 1 0-1.397 1.398h-.001c.03.04.062.078.098.115l3.85 3.85a1 1 0 0 0 1.415-1.414l-3.85-3.85a1.007 1.007 0 0 0-.115-.1zM12 6.5a5.5 5.5 0 1 1-11 0 5.5 5.5 0 0 1 11 0z"/> </svg><span class="visually-hidden">submit search</span></button>
              </div>
            </div>
          </form>
          
        </div>
    </div>
  </div>
</footer>

    <!-- Bootstrap JS bundle -->
<script src="/vra_2025/assets/lib/bootstrap.bundle.min.js"></script>
<!-- load other optional js -->


<script src="/vra_2025/assets/lib/lazysizes.min.js" async></script>
<script src="/vra_2025/assets/lib/spotlight.min.js" defer></script>
<script>
    // When the user scrolls down from the top of the document, show the button
    window.onscroll = function () {
        if (document.body.scrollTop > 500 || document.documentElement.scrollTop > 500) {
            document.getElementById("scroll-to-top").style.display = "block";
            document.getElementById("scroll-to-top").style.color = "#00448c"; // Change button color to #00448c
        } else {
            document.getElementById("scroll-to-top").style.display = "none";
        }
    }
    // scroll to top function
    function scrollToTop() {
        window.scroll({
            top: 0, 
            left: 0, 
            behavior: 'smooth'
        });
    }
</script>
<button id="scroll-to-top" type="button" class="btn btn-link btn-lg" onclick="scrollToTop();" title="Back to Top" aria-label="Back to Top">
    <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-up-square" viewBox="0 0 16 16"> <path fill-rule="evenodd" d="M15 2a1 1 0 0 0-1-1H2a1 1 0 0 0-1 1v12a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1V2zM0 2a2 2 0 0 1 2-2h12a2 2 0 0 1 2 2v12a2 2 0 0 1-2 2H2a2 2 0 0 1-2-2V2zm8.5 9.5a.5.5 0 0 1-1 0V5.707L5.354 7.854a.5.5 0 1 1-.708-.708l3-3a.5.5 0 0 1 .708 0l3 3a.5.5 0 0 1-.708.708L8.5 5.707V11.5z"/> </svg>
</button>



  </body>

</html>